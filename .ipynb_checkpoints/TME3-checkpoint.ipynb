{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,ClassifierMixin\n",
    "class linear(BaseEstimator,ClassifierMixin):\n",
    "    '''Classifieur linéaire de R^n -> R'''\n",
    "    def __init__(self, lam = 0.1, eps = 0.00001, dec = 1, ite = 1000, rand = np.random.RandomState()):\n",
    "        self.lam = lam\n",
    "        self.eps = eps\n",
    "        self.dec = dec\n",
    "        self.ite = ite\n",
    "        self.rand = rand\n",
    "        self.ini = False\n",
    "        \n",
    "    def init(self, n):\n",
    "        self.param = self.rand.rand(n+1)\n",
    "        self.gradHisto = np.zeros((1, n+1))\n",
    "        self.ini = True\n",
    "    \n",
    "    def fit(self, x, y, debug = False):\n",
    "        if len(x.shape) == 1 :\n",
    "            x = x.reshape((1,x.size))\n",
    "        if self.ini == False :\n",
    "            self.init(x.shape[1])\n",
    "        x = np.concatenate((np.ones((x.shape[0],1)), x),1)\n",
    "        '''ajout du biais'''\n",
    "        for it in range(self.ite):\n",
    "            n = self.rand.randint(0,x.shape[0])\n",
    "            delta = -2 * x[n] * y[n] + np.dot((np.dot(2 * x[n].T, x[n])), self.param).T + self.lam * np.sign(self.param)\n",
    "            self.gradHisto = np.concatenate((self.gradHisto, delta.reshape((1, -1))))\n",
    "            param2 = self.param - self.eps * delta\n",
    "            self.eps = self.eps * self.dec\n",
    "            if debug and it%(self.ite//10) == 0 :\n",
    "                print(np.mean((y-np.dot(x, self.param)) * (y-np.dot(x, self.param))))\n",
    "            for i in range(x.shape[1]):\n",
    "                if (self.param[i] * param2[i]) < 0:\n",
    "                    self.param[i] = 0\n",
    "                else :\n",
    "                    self.param[i] = param2[i]            \n",
    "                \n",
    "    def predict(self, x):\n",
    "        if len(x.shape) == 1 :\n",
    "            x = x.reshape((1,x.size))\n",
    "        if not self.ini:\n",
    "            self.init(x.shape[1])\n",
    "        x = np.concatenate((np.ones((x.shape[0],1)), x),1)\n",
    "        return np.rint(np.dot(x, self.param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.6619915051\n",
      "0.385081457066\n",
      "0.384683424269\n",
      "0.384595719336\n",
      "0.390157080446\n",
      "0.382859578729\n",
      "0.429476642142\n",
      "0.381143832985\n",
      "0.38192734701\n",
      "0.380155118081\n"
     ]
    }
   ],
   "source": [
    "c = linear(0, 0.0001, 1, 10000)\n",
    "c.fit(X, y, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.  1.  2.\n",
      "  1.  2.  1.  1.  1.  1.  1.  1.  1.  2.  2.  1.  1.  1.  2.  1.  1.  2.\n",
      "  1.  1.  1.  1.  2.  2.  1.  1.  1.  2.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(c.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.83388351,  -9.58763794,  -4.60344836,  -9.50437096,\n",
       "         -3.80409532],\n",
       "       [  1.07517778,   6.74307888,   3.07122648,   5.41013784,\n",
       "          1.88828188],\n",
       "       [ -0.67568208,  -7.95122659,  -4.90414415,  -7.67251691,\n",
       "         -4.16166388],\n",
       "       [ -1.60739843,  -9.33648372,  -3.51905408, -10.29394444,\n",
       "         -1.35145552],\n",
       "       [  0.20404223,   1.86519815,  -0.47707541,   2.18279853,\n",
       "          0.69228993],\n",
       "       [ -0.55226821,  -9.12398493,  -2.08546667,  -6.93264038,\n",
       "         -3.11879622],\n",
       "       [  0.06694051,   0.67034082,   1.55047112,   1.52697766,\n",
       "          0.67434215],\n",
       "       [ -1.87331395,  -9.35524995,  -3.8961765 ,  -9.18502635,\n",
       "         -4.22707712],\n",
       "       [ -0.24407717,  -7.11495723,   0.34443245,  -8.50794691,\n",
       "         -2.51501467]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.gradHisto[-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01565378,  0.09918137,  0.04474534,  0.08022998,  0.02807027])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.990004997839524e-05"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33333333,  0.4       ,  0.36666667,  0.36666667,  0.33333333])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = linear(0, 0.00001, 0.9999999, 10000)\n",
    "cross_validation.cross_val_score(c, X, y, cv=5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Bon l'algo converge mais les performances sont très moyenne, peut être parce que les données ne sont pas linéairement séparable mais je penche plutôt sur mon algo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36\n",
      "0.353333333333\n",
      "0.346666666667\n",
      "0.34\n",
      "0.333333333333\n",
      "0.333333333333\n",
      "0.333333333333\n",
      "0.333333333333\n",
      "0.333333333333\n",
      "0.333333333333\n",
      "0.333333333333\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0,1.1,0.1):\n",
    "    c = linear(i, 0.00001, 0.9999999, 10000)\n",
    "    print(np.mean(cross_validation.cross_val_score(c, X, y, cv=5, scoring=\"accuracy\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que les performances diminuent nettement avec l'augmentation de lambda, le modèle préférant limiter la taille de ses paramètres que les erreurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "s = []\n",
    "for i in np.arange(0,1.1,0.1):\n",
    "    c = linear(i, 0.00001, 0.9999999, 10000)\n",
    "    a.append(np.mean(cross_validation.cross_val_score(c, X, y, cv=5, scoring=\"accuracy\")))\n",
    "    '''cross_validation fais une copie du module, on est obligé de faire le fit nous même'''\n",
    "    c.fit(X, y)\n",
    "    s.append(c.param[c.param == 0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOWQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a936f73518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a,s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0075118 ,  0.08994211,  0.0365363 ,  0.07068901,  0.01951096])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme semble ne pas faire changer le signe des paramètres, il ne valent donc jamais 0, ce qui est étonant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

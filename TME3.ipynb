{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,ClassifierMixin\n",
    "class linear(BaseEstimator,ClassifierMixin):\n",
    "    '''Classifieur linéaire de R^n -> R'''\n",
    "    def __init__(self, lam = 0.1, eps = 0.001, dec = 1, ite = 1000, rand = np.random.RandomState()):\n",
    "        self.lam = lam\n",
    "        self.eps = eps\n",
    "        self.dec = dec\n",
    "        self.ite = ite\n",
    "        self.rand = rand\n",
    "        self.ini = False\n",
    "        \n",
    "    def init(self, n):\n",
    "        self.param = self.rand.rand(n+1) *2 -1\n",
    "        self.gradHisto = np.zeros((1, n+1))\n",
    "        self.ini = True\n",
    "    \n",
    "    def fit(self, x, y, debug = False):\n",
    "        if len(x.shape) == 1 :\n",
    "            x = x.reshape((1,x.size))\n",
    "        if self.ini == False :\n",
    "            self.init(x.shape[1])\n",
    "        x = np.concatenate((np.ones((x.shape[0],1)), x),1)\n",
    "        '''ajout du biais'''\n",
    "        for it in range(self.ite):\n",
    "            n = self.rand.randint(0,x.shape[0])\n",
    "            #delta = -2 * x[n] * y[n] + np.dot((np.dot(2 * x[n].T, x[n])), self.param).T + self.lam * np.sign(self.param)\n",
    "            delta = -2 * x[n] * y[n] + x[n]*2*np.dot(x[n],self.param) + self.lam * np.sign(self.param)\n",
    "            self.gradHisto = np.concatenate((self.gradHisto, delta.reshape((1, -1))))\n",
    "            param2 = self.param - self.eps * delta\n",
    "            '''self.param = self.param - self.eps * delta'''\n",
    "            self.eps = self.eps * self.dec\n",
    "            if debug and it%(self.ite//10) == 0 :\n",
    "                print(np.mean((y-np.dot(x, self.param)) * (y-np.dot(x, self.param))))\n",
    "            for i in range(x.shape[1]):\n",
    "                if (self.param[i] * param2[i]) < 0:\n",
    "                    self.param[i] = 0\n",
    "                else :\n",
    "                    self.param[i] = param2[i]         \n",
    "                \n",
    "    def predict(self, x):\n",
    "        if len(x.shape) == 1 :\n",
    "            x = x.reshape((1,x.size))\n",
    "        if not self.ini:\n",
    "            self.init(x.shape[1])\n",
    "        x = np.concatenate((np.ones((x.shape[0],1)), x),1)\n",
    "        return np.rint(np.dot(x, self.param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.687020247513\n",
      "0.109179424385\n",
      "0.0922460988456\n",
      "0.0811985420925\n",
      "0.0729734217549\n",
      "0.0678061447033\n",
      "0.0684885019801\n",
      "0.0576916036068\n",
      "0.0671194268498\n",
      "0.0534263366108\n"
     ]
    }
   ],
   "source": [
    "c = linear(0, 0.001, 1, 10000)\n",
    "c.fit(X, y, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0. -0. -0. -0.  0.\n",
      "  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0. -0.  0. -0.\n",
      " -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  2.  1.\n",
      "  1.  1.  2.  1.  1.  1.  1.  1.  1.  2.  1.  1.  2.  1.  2.  1.  2.  1.\n",
      "  2.  1.  1.  1.  1.  2.  2.  1.  1.  1.  1.  2.  2.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(c.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.73847865,  4.43087189,  2.14158808,  3.32315392,  1.10771797],\n",
       "       [-0.23488359, -1.47976659, -0.79860419, -1.31534808, -0.5637206 ],\n",
       "       [-0.16821693, -0.87472805, -0.58875926, -0.2523254 , -0.03364339],\n",
       "       [-0.35385551, -1.84004864, -1.45080758, -0.53078326, -0.03538555],\n",
       "       [-0.21170169, -1.35489084, -0.59276474, -1.18552949, -0.44457356],\n",
       "       [-0.61675083, -3.63882992, -1.8502525 , -3.14542925, -1.1101515 ],\n",
       "       [-0.12733679, -0.94229226, -0.35654302, -0.77675443, -0.24193991],\n",
       "       [-0.50549986, -3.48794906, -1.56704958, -2.57804931, -1.16264969],\n",
       "       [-0.18660806, -0.85839708, -0.67178902, -0.18660806, -0.03732161]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.gradHisto[-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.52076474, -0.13820785, -0.10822612,  0.36866622,  0.31012005])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.93333333,  0.93333333,  0.93333333,  0.86666667,  0.96666667])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = linear(0, 0.001, 0.999999, 10000)\n",
    "cross_validation.cross_val_score(c, X, y, cv=5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Bon l'algo converge mais les performances sont très moyenne, peut être parce que les données ne sont pas linéairement séparable mais je penche plutôt sur mon algo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.946666666667\n",
      "0.946666666667\n",
      "0.906666666667\n",
      "0.886666666667\n",
      "0.866666666667\n",
      "0.86\n",
      "0.853333333333\n",
      "0.833333333333\n",
      "0.826666666667\n",
      "0.793333333333\n",
      "0.786666666667\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0,1.1,0.1):\n",
    "    c = linear(i, 0.001, 0.999999, 10000)\n",
    "    print(np.mean(cross_validation.cross_val_score(c, X, y, cv=5, scoring=\"accuracy\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que les performances diminuent nettement avec l'augmentation de lambda, le modèle préférant limiter la taille de ses paramètres que les erreurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = []\n",
    "s = []\n",
    "for i in np.arange(0,10,1):\n",
    "    c = linear(i, 0.001, 0.9999999, 10000)\n",
    "    a.append(np.mean(cross_validation.cross_val_score(c, X, y, cv=5, scoring=\"accuracy\")))\n",
    "    '''cross_validation fais une copie du module, on est obligé de faire le fit nous même'''\n",
    "    c.fit(X, y)\n",
    "    s.append(c.param[c.param == 0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktT6/5D0t0PjIBn8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f22226f7c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(a,s)\n",
    "plt.ylabel(\"Nb de 0\")\n",
    "plt.xlabel(\"score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.9008476325\n",
      "1.67145059056\n",
      "1.39373826139\n",
      "1.67132147955\n",
      "1.39185806394\n",
      "1.38158482891\n",
      "1.38431183625\n",
      "1.67644135316\n",
      "1.53807398685\n",
      "1.55261211478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.02607279,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = linear(100, 0.001, 1, 10000)\n",
    "c.fit(X, y, True)\n",
    "c.param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
